{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Go through the basics of creating a Python script, and then create a Python file for the script to run it on the terminal. In this practice notebook, you'll create the building blocks for a script that finds large files on the filesytem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the logic right \n",
    "Start by defining some of the requirements of the script. In this case, we need to:\n",
    "- _Walk_ the filesystem looking at files, directories and sub-directories\n",
    "- Capture file information: is it a file? a directory? what size? what path?\n",
    "- Store that information in a suitable data structure\n",
    "- Report the sorted data what are the largest files by looking at the data structure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# The os module is perfect for filesystem operations like \"walking\" throught directories and files\n",
    "# Although there are many ways of achieving the same effect, a good way to loop over the filesystem is using `os.walk()`\n",
    "import os\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        print(f\"File found: {_file}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File found: README.md\n",
      "File found: .gitignore\n",
      "File found: config\n",
      "File found: HEAD\n",
      "File found: index\n",
      "File found: packed-refs\n",
      "File found: pack-734108524c45bcbe06adc07ac04de3821b9505bd.pack\n",
      "File found: pack-734108524c45bcbe06adc07ac04de3821b9505bd.idx\n",
      "File found: HEAD\n",
      "File found: main\n",
      "File found: HEAD\n",
      "File found: main\n",
      "File found: HEAD\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Update the loop so that it shows the absolute path of a file ignoring directories which we aren't going to track\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        print(f\"File found: {full_path}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File found: ./README.md\n",
      "File found: ./.gitignore\n",
      "File found: ./.git/config\n",
      "File found: ./.git/HEAD\n",
      "File found: ./.git/index\n",
      "File found: ./.git/packed-refs\n",
      "File found: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.pack\n",
      "File found: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.idx\n",
      "File found: ./.git/logs/HEAD\n",
      "File found: ./.git/logs/refs/heads/main\n",
      "File found: ./.git/logs/refs/remotes/origin/HEAD\n",
      "File found: ./.git/refs/heads/main\n",
      "File found: ./.git/refs/remotes/origin/HEAD\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So now we have a few objectives completed:\n",
    "- Files are detected\n",
    "- Full paths are being collected\n",
    "\n",
    "Next, we need to find size information. Python uses bytes by default for size, so in addition to capturing the size, we'll need to find a way to change bytes to megabytes or gigabytes to make it easier to read"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Update the loop to include the file size\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        size = os.path.getsize(full_path)\n",
    "        print(f\"Size: {size}b - File: {full_path}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size: 61b - File: ./README.md\n",
      "Size: 1799b - File: ./.gitignore\n",
      "Size: 328b - File: ./.git/config\n",
      "Size: 21b - File: ./.git/HEAD\n",
      "Size: 217b - File: ./.git/index\n",
      "Size: 112b - File: ./.git/packed-refs\n",
      "Size: 1654b - File: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.pack\n",
      "Size: 1184b - File: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.idx\n",
      "Size: 186b - File: ./.git/logs/HEAD\n",
      "Size: 186b - File: ./.git/logs/refs/heads/main\n",
      "Size: 186b - File: ./.git/logs/refs/remotes/origin/HEAD\n",
      "Size: 41b - File: ./.git/refs/heads/main\n",
      "Size: 30b - File: ./.git/refs/remotes/origin/HEAD\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Persist the data into a dictionary. Since file paths are unique you can use those as dictionary keys\n",
    "file_metadata = {}\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        size = os.path.getsize(full_path)\n",
    "        file_metadata[full_path] = size\n",
    "print(file_metadata)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'./large-files.ipynb': 5358, './README.md': 61, './.gitignore': 1799, './.git/config': 328, './.git/HEAD': 21, './.git/index': 217, './.git/packed-refs': 112, './.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.pack': 1654, './.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.idx': 1184, './.git/logs/HEAD': 186, './.git/logs/refs/heads/main': 186, './.git/logs/refs/remotes/origin/HEAD': 186, './.git/refs/heads/main': 41, './.git/refs/remotes/origin/HEAD': 30}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the metadata is captured and stored in a suitable data structure like a dictionary, report back the results with only the four largest files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "items_shown = 0\n",
    "    \n",
    "for path, size in sorted(file_metadata.items(), key=lambda x:x[1], reverse=True):\n",
    "    if items_shown > 4:\n",
    "        break\n",
    "    print(f\"Size: {size} Path: {path}\")\n",
    "    items_shown += 1\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size: 5358 Path: ./large-files.ipynb\n",
      "Size: 1799 Path: ./.gitignore\n",
      "Size: 1654 Path: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.pack\n",
      "Size: 1184 Path: ./.git/objects/pack/pack-734108524c45bcbe06adc07ac04de3821b9505bd.idx\n",
      "Size: 328 Path: ./.git/config\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a lot happening in the previous cell. `sorted()` is a built-in function that can sort iterables like Python dictionaries. In this case, we need to sort by the _value_. This is done using the `key` parameter which accepts a `lambda`.\n",
    "`lambda` allows to represent a function in a single line without defining it. That `lambda` expression is the same as defining a function like:\n",
    "\n",
    "```python\n",
    "def by_value(x):\n",
    "    return x[1]\n",
    "```\n",
    "\n",
    "`x` represents two items, the path and the size. The function is returning only the size because that is what we want to sort with. Try changing the `lambda` expression to use `x[0]` instead and see what happens."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tmp': conda)"
  },
  "interpreter": {
   "hash": "904aaa8d64bef68f2ffda03272599bba12aa237240eb8594526423b3c4f1b9a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}